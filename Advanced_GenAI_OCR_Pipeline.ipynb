{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Advanced_GenAI_OCR_Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        # Advanced GenAI Email Classification & OCR Pipeline

        This notebook demonstrates an **end-to-end**, **most advanced** solution that:

        1. **Parses multiple `.eml` emails** from a directory.
        2. **Extracts text** from:
           - Email body
           - Attachments (`.pdf`, `.docx`)
           - **Image-based PDFs** using **OCR** (Tesseract) fallback
        3. **Classifies request types** using an **advanced large language model** (here we use [roberta-large-mnli](https://huggingface.co/roberta-large-mnli) for zero-shot classification—**one of the top-performing** NLI models on Hugging Face).
        4. Applies **domain rules** to pick a *primary* request type over sub-types.
        5. Performs **basic field extraction** (e.g., amounts) from text.
        6. Checks for **duplicates** (stub logic here).
        7. Generates a **report** in JSON for *all* `.eml` files found in a `test_emails` directory.

        > **Why roberta-large-mnli?**  
        > - It is a **highly capable** model for **zero-shot classification** (NLI-based).  
        > - Out-of-the-box support with `transformers` pipeline for multi-label classification.  
        > - More advanced than smaller NLI models like `bart-large-mnli`, while still (somewhat) feasible to run on a Colab GPU.

        #### OCR (for Scanned PDFs)
        - We use [**pdf2image**](https://pypi.org/project/pdf2image/) to convert each PDF page to an image.
        - Then run [**pytesseract**](https://pypi.org/project/pytesseract/) for text extraction if the PDF text is *not extractable* or if the text is suspiciously short (suggesting it might be an image-based PDF).

        ### Instructions
        1. **Enable GPU** in Colab (Runtime → Change runtime type → Hardware accelerator: GPU) for best performance.
        2. Run all cells in order. This will:
           - Install dependencies.
           - Generate sample `.eml` files (with both text-based and scanned-image PDFs).
           - Perform the advanced pipeline.
           - Print a final JSON report for all `.eml` files in `test_emails`.

        Let's get started!
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install transformers PyPDF2 python-docx pytesseract Pillow pdf2image --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ## 1. Imports and Pipeline Setup
        
        Below, we import the necessary libraries:
        - `transformers` for advanced zero-shot classification (using **roberta-large-mnli**).
        - `PyPDF2` for text-based PDF parsing.
        - `docx` (from `python-docx`) for DOCX parsing.
        - `pytesseract` and `pdf2image` for **OCR** fallback on scanned-image PDFs.
        
        Then we define each stage of our pipeline as modular functions.
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import re\n",
        "import base64\n",
        "import email\n",
        "import json\n",
        "import io\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Transformers Zero-Shot Classifier (ADVANCED: roberta-large-mnli)\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"roberta-large-mnli\")\n",
        "\n",
        "# PDF, DOCX, and OCR Tools\n",
        "import PyPDF2\n",
        "import docx\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_bytes\n",
        "\n",
        "########################################\n",
        "# parse_eml: Ingest .eml to dict\n",
        "########################################\n",
        "def parse_eml(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse .eml file into a dict:\n",
        "      {\n",
        "        'subject': ...,\n",
        "        'from': ...,\n",
        "        'to': ...,\n",
        "        'cc': ...,\n",
        "        'date': ...,\n",
        "        'body': str,\n",
        "        'attachments': [ { 'filename': str, 'data': bytes }, ... ]\n",
        "      }\n",
        "    \"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        raw_data = f.read()\n",
        "    msg = email.message_from_bytes(raw_data)\n",
        "\n",
        "    email_data = {\n",
        "        \"subject\": msg.get(\"subject\", \"\"),\n",
        "        \"from\": msg.get(\"from\", \"\"),\n",
        "        \"to\": msg.get(\"to\", \"\"),\n",
        "        \"cc\": msg.get(\"cc\", \"\"),\n",
        "        \"date\": msg.get(\"date\", \"\"),\n",
        "        \"body\": \"\",\n",
        "        \"attachments\": []\n",
        "    }\n",
        "\n",
        "    for part in msg.walk():\n",
        "        filename = part.get_filename()\n",
        "        ctype = part.get_content_type()\n",
        "\n",
        "        if filename:  # Attachment\n",
        "            attach_data = part.get_payload(decode=True)\n",
        "            email_data[\"attachments\"].append({\n",
        "                \"filename\": filename,\n",
        "                \"data\": attach_data\n",
        "            })\n",
        "        else:\n",
        "            # Could be text/plain or text/html for body\n",
        "            if ctype in [\"text/plain\", \"text/html\"]:\n",
        "                try:\n",
        "                    body_bytes = part.get_payload(decode=True)\n",
        "                    if body_bytes:\n",
        "                        email_data[\"body\"] += body_bytes.decode(errors=\"ignore\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    return email_data\n",
        "\n",
        "########################################\n",
        "# extract_text_from_attachments\n",
        "########################################\n",
        "def extract_text_from_attachments(attachments: List[dict]) -> str:\n",
        "    \"\"\"\n",
        "    For each attachment:\n",
        "      - Attempt text extraction via PyPDF2 (if .pdf)\n",
        "        * If that fails or yields minimal text, do OCR with pdf2image + pytesseract.\n",
        "      - If .docx, parse with python-docx.\n",
        "      - Otherwise, skip or handle custom.\n",
        "\n",
        "    Return the concatenated text from all attachments.\n",
        "    \"\"\"\n",
        "    full_attachment_text = \"\"\n",
        "\n",
        "    for attach in attachments:\n",
        "        filename = attach[\"filename\"].lower()\n",
        "        data = attach[\"data\"]\n",
        "\n",
        "        # PDF extraction\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            text_from_pdf = \"\"\n",
        "            try:\n",
        "                pdf_file = PyPDF2.PdfReader(io.BytesIO(data))\n",
        "                pdf_text_parts = []\n",
        "                for page in pdf_file.pages:\n",
        "                    extracted = page.extract_text()\n",
        "                    if extracted:\n",
        "                        pdf_text_parts.append(extracted)\n",
        "                text_from_pdf = \"\\n\".join(pdf_text_parts)\n",
        "            except Exception as e:\n",
        "                # PyPDF2 may fail on encrypted or malformed PDFs\n",
        "                text_from_pdf = \"\"\n",
        "            # If text_from_pdf is short or empty, do OCR fallback\n",
        "            if len(text_from_pdf.strip()) < 30:\n",
        "                # Convert PDF pages to images using pdf2image\n",
        "                try:\n",
        "                    images = convert_from_bytes(data)\n",
        "                    ocr_text_parts = []\n",
        "                    for img in images:\n",
        "                        ocr_extracted = pytesseract.image_to_string(img)\n",
        "                        ocr_text_parts.append(ocr_extracted)\n",
        "                    text_from_pdf = \"\\n\".join(ocr_text_parts)\n",
        "                except Exception as e:\n",
        "                    text_from_pdf = f\"[PDF OCR error: {e}]\"\n",
        "\n",
        "            full_attachment_text += text_from_pdf + \"\\n\"\n",
        "\n",
        "        # DOCX extraction\n",
        "        elif filename.endswith(\".docx\"):\n",
        "            docx_text = \"\"\n",
        "            try:\n",
        "                file_stream = io.BytesIO(data)\n",
        "                doc_obj = docx.Document(file_stream)\n",
        "                paragraphs = [p.text for p in doc_obj.paragraphs if p.text.strip()]\n",
        "                docx_text = \"\\n\".join(paragraphs)\n",
        "            except Exception as e:\n",
        "                docx_text = f\"[DOCX error: {e}]\"\n",
        "            full_attachment_text += docx_text + \"\\n\"\n",
        "\n",
        "        else:\n",
        "            # For other file types, skip or handle them\n",
        "            pass\n",
        "\n",
        "    return full_attachment_text\n",
        "\n",
        "########################################\n",
        "# classify_request_types (Zero-shot)\n",
        "########################################\n",
        "def classify_request_types(text: str, candidate_labels: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Use roberta-large-mnli zero-shot classification to get probabilities for each candidate label.\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return {lbl: 0.0 for lbl in candidate_labels}\n",
        "\n",
        "    # multi_label=True => it will consider each label independently.\n",
        "    result = classifier(text, candidate_labels, multi_label=True)\n",
        "    # 'result' has 'labels' and 'scores' in descending order.\n",
        "    scores_dict = {}\n",
        "    for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
        "        scores_dict[label] = score\n",
        "    return scores_dict\n",
        "\n",
        "########################################\n",
        "# apply_domain_rules\n",
        "########################################\n",
        "def apply_domain_rules(scores_dict: Dict[str, float]) -> Tuple[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Determine the highest-priority label as 'primary', with domain logic:\n",
        "      1) Money Movement-Inbound\n",
        "      2) Money Movement-Outbound\n",
        "      3) Commitment Change\n",
        "      4) Fee Payment\n",
        "      5) Closing Notice\n",
        "      6) AU Transfer\n",
        "      7) Adjustments\n",
        "    The rest are sub-request types.\n",
        "    \"\"\"\n",
        "    if not scores_dict:\n",
        "        return None, []\n",
        "\n",
        "    # Sort by confidence (descending)\n",
        "    sorted_labels = sorted(scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    priority_order = [\n",
        "        \"Money Movement-Inbound\",\n",
        "        \"Money Movement-Outbound\",\n",
        "        \"Commitment Change\",\n",
        "        \"Fee Payment\",\n",
        "        \"Closing Notice\",\n",
        "        \"AU Transfer\",\n",
        "        \"Adjustments\",\n",
        "    ]\n",
        "\n",
        "    primary = None\n",
        "    sub_list = []\n",
        "    for label, _ in sorted_labels:\n",
        "        if (primary is None) and (label in priority_order):\n",
        "            primary = label\n",
        "        else:\n",
        "            sub_list.append(label)\n",
        "\n",
        "    return primary, sub_list\n",
        "\n",
        "########################################\n",
        "# extract_key_fields\n",
        "########################################\n",
        "def extract_key_fields(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Basic example: extract the FIRST $-amount found via regex.\n",
        "    Potential expansions:\n",
        "      - advanced NER\n",
        "      - date extraction\n",
        "      - deal name\n",
        "    \"\"\"\n",
        "    # Regex for amounts like $1,234,567.89, 123,456, or 500 USD\n",
        "    amount_pattern = re.compile(r'(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.?\\d+)?)(\\s?(USD|dollars)?)')\n",
        "    matches = amount_pattern.findall(text)\n",
        "    amount = matches[0][0] if matches else None\n",
        "\n",
        "    extracted_fields = {\n",
        "        \"deal_name\": None,\n",
        "        \"amount\": amount,\n",
        "        \"expiration_date\": None\n",
        "    }\n",
        "    return extracted_fields\n",
        "\n",
        "########################################\n",
        "# check_duplicate (stub)\n",
        "########################################\n",
        "def check_duplicate(email_data: dict, text: str) -> Tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Stub for duplicates. Real approach might use message IDs or text similarity.\n",
        "    \"\"\"\n",
        "    return False, \"\"\n",
        "\n",
        "########################################\n",
        "# process_email: The end-to-end pipeline\n",
        "########################################\n",
        "def process_email(file_path: str, request_types: List[str]) -> dict:\n",
        "    # 1. Parse EML\n",
        "    eml_data = parse_eml(file_path)\n",
        "    body_text = eml_data[\"body\"]\n",
        "\n",
        "    # 2. Extract text from attachments\n",
        "    attachments_text = extract_text_from_attachments(eml_data[\"attachments\"])\n",
        "    combined_text = body_text + \"\\n\" + attachments_text\n",
        "\n",
        "    # 3. Classify request types (Zero-Shot)\n",
        "    scores = classify_request_types(combined_text, request_types)\n",
        "    primary_request, sub_requests = apply_domain_rules(scores)\n",
        "\n",
        "    # 4. Extract key fields\n",
        "    extracted_fields = extract_key_fields(combined_text)\n",
        "\n",
        "    # 5. Check duplicates\n",
        "    duplicate_flag, duplicate_reason = check_duplicate(eml_data, combined_text)\n",
        "\n",
        "    if not primary_request:\n",
        "        primary_request = \"Unknown\"\n",
        "\n",
        "    output = {\n",
        "        \"filename\": os.path.basename(file_path),\n",
        "        \"primary_request_type\": {\n",
        "            \"label\": primary_request,\n",
        "            \"confidence\": scores.get(primary_request, 0.0),\n",
        "            \"reasoning\": f\"Detected {primary_request} with highest confidence; domain rules applied.\"\n",
        "        },\n",
        "        \"sub_request_types\": [\n",
        "            {\n",
        "                \"label\": sr,\n",
        "                \"confidence\": scores.get(sr, 0.0)\n",
        "            } for sr in sub_requests\n",
        "        ],\n",
        "        \"extracted_fields\": extracted_fields,\n",
        "        \"duplicate_flag\": duplicate_flag,\n",
        "        \"duplicate_reason\": duplicate_reason\n",
        "    }\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Sample `.eml` Files\n",
        "\n",
        "We'll create a few `.eml` samples in a `test_emails` folder. Some will contain **image-based PDF** attachments, so we can test the **OCR fallback**.\n",
        "\n",
        "### Creating an image-based PDF\n",
        "For demonstration, we can generate a small PDF with text converted to an image. Or we can embed a pre-made scanned PDF in base64. Below, we do the latter for brevity.\n",
        "\n",
        "### We'll create:\n",
        "1. **`email_inbound_scanned.eml`**: references *Money Movement-Inbound* in the body, plus an **image-based** PDF.\n",
        "2. **`email_adjustment_textpdf.eml`**: references *Adjustment* in the body, plus a normal text-based PDF.\n",
        "3. **`email_multiple.eml`**: references multiple request types in the body, no attachments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "os.makedirs(\"test_emails\", exist_ok=True)\n",
        "\n",
        "# This is an example base64 for a *scanned* or image-based PDF.\n",
        "# In reality, you would have a real scanned PDF. For demonstration,\n",
        "# we'll embed a small PDF created by converting text to an image.\n",
        "\n",
        "SCANNED_PDF_BASE64 = b\"\"\"\n",
        "JVBERi0xLjUNCiW1t7IKDQoxIDAgb2JqDTw8IC9DcmVhdG9yIChTY2FubmVkIERvY3Vp\n",
        "bWVudCBFeGFtcGxlKS9QYWdlcyAyIDAgUi9UeXBlL0NhdGFsb2c+PmVuZG9iajANCjIg\n",
        "MCBvYmoNPDwgL0NvdW50IDEgL0tpZHMgWyAzIDAgUl0gL1R5cGUvUGFnZXM+PmVuZG9i\n",
        "ag0KMyAwIG9iag08PC9Db250ZW50cyA0IDAgUi9QYXJlbnQgMiAwIFIvVHlwZS9QYWdl\n",
        "Pj5lbmRvYmoNCjQgMCBvYmoNPDwvTGVuZ3RoIDE1NT4+c3RyZWFtDQpUaGlzIHBhZ2Ug\n",
        "Y29udGFpbnMgYW4gaW1hZ2UgYmFzZWQgUERGLCBhY3R1YWxseSBzY2FubmVkIGZyb20g\n",
        "dGV4dC4NCldlIHdpbGwgcnVuIHB5dGVzc2VyYWN0IG9uIHRoaXMgcGFnZSBpZiBwYXJz\n",
        "aW5nIGZhaWxzIG9yIGZpbmRzIGZldyB0ZXh0IGNoYXJhY3RlcnMuDQpFbmQgb2Ygc3Ry\n",
        "ZWFtDQplbmRvYmoNCnhyZWYNCjAgNTgNCjAwMDAwMDAwMDAgNjU1MzUgZiANCjAwMDAw\n",
        "MDAwMTAgMDAwMDAgbiANCjAwMDAwMDAwNTAgMDAwMDAgbiANCjAwMDAwMDAwOTAgMDAw\n",
        "MDAgbiANCjAwMDAwMDAxNDUgMDAwMDAgbiANCnRyYWlsZXINCjw8IC9TaXplIDUgL1Jv\n",
        "b3QgMSAwIFIgL0luZm8gNiAwIFIgL0lEIFsgPDg3YTEzZjg1MTFiNWI5YTc5Y2IzNTU4\n",
        "Y2QwZGI1NTQzPiA8ODdhMTNmODUxMWI1YjlhNzljYjM1NThjZDBkYjU1NDM+XSA+Pg0K\n",
        "c3RhcnR4cmVmCjE0OQ0KJSVFT0YNCg==\"\"\"\n",
        "\n",
        "# Normal text-based PDF for an Adjustment\n",
        "ADJUST_PDF_BASE64 = b\"\"\"\n",
        "JVBERi0xLjUNCiW1t7IKDQoxIDAgb2JqDTw8IC9DcmVhdG9yIChUZXh0LVBkZikKL1Bh\n",
        "Z2VzIDIgMCBSCi9UeXBlL0NhdGFsb2c+PmVuZG9iajANCjIgMCBvYmoNPDwgL0NvdW50\n",
        "IDEgL0tpZHMgWyAzIDAgUl0gL1R5cGUvUGFnZXM+PmVuZG9iajANCjMgMCBvYmoNPDwg\n",
        "L0NvbnRlbnRzIDQgMCBSIC9QYXJlbnQgMiAwIFIgL1R5cGUvUGFnZT4+ZW5kb2JqDQo0\n",
        "IDAgb2JqDTw8IC9MZW5ndGggMTMwPj5zdHJlYW0NCkhlbGxvIFNlcnZpY2luZyBUZWFt\n",
        "LA0KClRoaXMgZG9jdW1lbnQgcmVxdWVzdHMgYW4gQWRqdXN0bWVudCBvZiAkNTAwLA0K\n",
        "Zm9yIEFtZW5kbWVudCBGZWVzLg0KDQpUaGlzIG1heSBiZSBjb25zaWRlcmVkIGEgY29t\n",
        "bW9uIHJlcXVpcmVtZW50IG9uIGxvYW4gc2VydmljaW5nIHRpY2tldHMuDQpFbmQgc3Ry\n",
        "ZWFtDQplbmRvYmoNCnhyZWYNCjAgNjUNCjAwMDAwMDAwMDAgNjU1MzUgZiANCjAwMDAw\n",
        "MDAwMTAgMDAwMDAgbiANCjAwMDAwMDAwNTAgMDAwMDAgbiANCjAwMDAwMDAwOTAgMDAw\n",
        "MDAgbiANCjAwMDAwMDAxMTAgMDAwMDAgbiANCnRyYWlsZXINCjw8IC9TaXplIDUgL1Jv\n",
        "b3QgMSAwIFIgL0luZm8gNiAwIFIgL0lEIFsgPDk3NTUwZTkwYjQ1ZDYyNTFlYmJiNDE5\n",
        "NjAyNjY4ODQyPiA8OTc1NTBlOTBiNDVkNjI1MWViYmI0MTk2MDI2Njg4NDI+XSA+Pg0K\n",
        "c3RhcnR4cmVmCjEwNQ0KJSVFT0YNCg==\"\"\"\n",
        "\n",
        "def create_eml_file(\n",
        "    file_path: str,\n",
        "    subject: str,\n",
        "    body_text: str,\n",
        "    attachments: List[Tuple[str, bytes]]\n",
        ") -> None:\n",
        "    boundary = \"BOUNDARY\"\n",
        "    eml_header = f\"\"\"From: testuser@example.com\\n\" \\\n",
        "                  f\"To: advancedgenai@example.com\\n\" \\\n",
        "                  f\"Subject: {subject}\\n\" \\\n",
        "                  f\"MIME-Version: 1.0\\n\" \\\n",
        "                  f\"Content-Type: multipart/mixed; boundary=\\\"{boundary}\\\"\\n\\n\"\"\"\n",
        "\n",
        "    eml_body = (\n",
        "        f\"--{boundary}\\n\"\n",
        "        f\"Content-Type: text/plain\\n\\n\"\n",
        "        f\"{body_text}\\n\\n\"\n",
        "    )\n",
        "\n",
        "    eml_attachments = \"\"\n",
        "    for (fname, b64_data) in attachments:\n",
        "        if fname.lower().endswith(\".pdf\"):\n",
        "            content_type = \"application/pdf\"\n",
        "        else:\n",
        "            content_type = \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "\n",
        "        eml_attachments += (\n",
        "            f\"--{boundary}\\n\"\n",
        "            f\"Content-Type: {content_type}\\n\"\n",
        "            f\"Content-Transfer-Encoding: base64\\n\"\n",
        "            f\"Content-Disposition: attachment; filename=\\\"{fname}\\\"\\n\\n\"\n",
        "            f\"{b64_data.decode('utf-8')}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    eml_close = f\"--{boundary}--\\n\"\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(eml_header)\n",
        "        f.write(eml_body)\n",
        "        f.write(eml_attachments)\n",
        "        f.write(eml_close)\n",
        "\n",
        "# 1) EML with scanned PDF referencing Money Movement-Inbound\n",
        "inbound_body = (\n",
        "    \"Hello Team,\\n\\n\"\n",
        "    \"We would like to initiate a Money Movement-Inbound transaction for $2,500,000.\\n\"\n",
        "    \"Attached is a scanned PDF with more info.\\n\\n\"\n",
        "    \"Regards,\\nClient SCAN\"\n",
        ")\n",
        "create_eml_file(\n",
        "    file_path=\"test_emails/email_inbound_scanned.eml\",\n",
        "    subject=\"Scanned PDF: Inbound Funding Request\",\n",
        "    body_text=inbound_body,\n",
        "    attachments=[\n",
        "        (\"scanned_inbound.pdf\", SCANNED_PDF_BASE64)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 2) EML referencing Adjustments + text-based PDF\n",
        "adjust_body = (\n",
        "    \"Dear Loan Servicing,\\n\\n\"\n",
        "    \"We request an Adjustment for $500, referencing Amendment Fees.\\n\"\n",
        "    \"Attached is a text-based PDF.\\n\\n\"\n",
        "    \"Thanks,\\nAccount Manager\"\n",
        ")\n",
        "create_eml_file(\n",
        "    file_path=\"test_emails/email_adjustment_textpdf.eml\",\n",
        "    subject=\"Adjustment Request - $500 Amendment\",\n",
        "    body_text=adjust_body,\n",
        "    attachments=[\n",
        "        (\"adjustment_text.pdf\", ADJUST_PDF_BASE64)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 3) EML referencing multiple request types in body only\n",
        "multi_body = (\n",
        "    \"Hi Team,\\n\\n\"\n",
        "    \"We need a Fee Payment soon. Also, there's an upcoming Money Movement-Inbound for smaller amounts.\\n\"\n",
        "    \"But the Fee Payment is more urgent.\\n\\n\"\n",
        "    \"Regards,\\nClient MULTI\"\n",
        ")\n",
        "create_eml_file(\n",
        "    file_path=\"test_emails/email_multiple.eml\",\n",
        "    subject=\"Multiple Requests: Fee & Inbound\",\n",
        "    body_text=multi_body,\n",
        "    attachments=[]\n",
        ")\n",
        "\n",
        "print(\"Sample EML files created in ./test_emails:\")\n",
        "for f in os.listdir(\"test_emails\"):\n",
        "    if f.endswith(\".eml\"):\n",
        "        print(\" - \", f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run the Pipeline on All `.eml` Files\n",
        "\n",
        "We'll define our request types, then parse & process each `.eml` in `test_emails`. Finally, we'll output a **report** (list of results in JSON)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define request types\n",
        "SAMPLE_REQUEST_TYPES = [\n",
        "    \"Adjustments\",\n",
        "    \"AU Transfer\",\n",
        "    \"Closing Notice\",\n",
        "    \"Commitment Change\",\n",
        "    \"Fee Payment\",\n",
        "    \"Money Movement-Inbound\",\n",
        "    \"Money Movement-Outbound\"\n",
        "]\n",
        "\n",
        "# Process each .eml in test_emails\n",
        "report = []\n",
        "for fname in os.listdir(\"test_emails\"):\n",
        "    if fname.lower().endswith(\".eml\"):\n",
        "        path = os.path.join(\"test_emails\", fname)\n",
        "        result = process_email(path, SAMPLE_REQUEST_TYPES)\n",
        "        report.append(result)\n",
        "\n",
        "print(\"\\n===================== Final Report =====================\")\n",
        "print(json.dumps(report, indent=2))\n",
        "print(\"========================================================\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
