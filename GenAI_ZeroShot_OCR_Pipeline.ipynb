{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "GenAI_ZeroShot_OCR_Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-End GenAI Email Classification & OCR Pipeline\n",
        "\n",
        "This notebook demonstrates an **end-to-end** solution to:\n",
        "1. Parse multiple `.eml` emails from a directory.\n",
        "2. Extract text from the email body and attachments (PDF/DOCX).\n",
        "3. Classify request types using an **open-source Zero-Shot** model.\n",
        "4. Apply domain rules to determine primary vs. sub-request types.\n",
        "5. Perform **basic field extraction** (e.g., amounts).\n",
        "6. (Optional) Perform **OCR** for scanned PDFs, if needed.\n",
        "7. Generate a **report** summarizing results for all `.eml` files.\n",
        "\n",
        "### Libraries & Installation\n",
        "- **transformers** for zero-shot classification.\n",
        "- **PyPDF2** for extracting text from PDFs.\n",
        "- **python-docx** for extracting text from DOCX.\n",
        "- **pytesseract** & **PIL** (optional) if you need OCR on image-based PDFs.\n",
        "\n",
        "You can install them with:\n",
        "```\n",
        "!pip install transformers PyPDF2 python-docx pytesseract Pillow\n",
        "```\n",
        "The code here will demonstrate a purely text-based PDF by default. If you have scanned-image PDFs, you can enable the Tesseract-based OCR code snippet (commented out below).\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers PyPDF2 python-docx pytesseract Pillow --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Pipeline Setup\n",
        "\n",
        "We import the core libraries for parsing emails, performing zero-shot classification, and extracting text from PDF/DOCX attachments.\n",
        "\n",
        "> **Note**: For demonstration, we embed sample `.eml` files **directly in this notebook**, each containing attachments in Base64. We'll write them out to a `test_emails` folder so that we can parse them as if they were real emails.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import re\n",
        "import base64\n",
        "import email\n",
        "import json\n",
        "import io\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "#######################################\n",
        "# Transformers Zero-Shot Classifier\n",
        "#######################################\n",
        "from transformers import pipeline\n",
        "# Initialize the pipeline (using bart-large-mnli as an example)\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "#######################################\n",
        "# PDF, DOCX, and optional OCR (Tesseract)\n",
        "#######################################\n",
        "import PyPDF2\n",
        "import docx\n",
        "\n",
        "# OPTIONAL: If you need OCR for image-based PDFs\n",
        "# import pytesseract\n",
        "# from PIL import Image\n",
        "\n",
        "#######################################\n",
        "# Utility: parse_eml\n",
        "#######################################\n",
        "def parse_eml(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse .eml file and return a dictionary of:\n",
        "      {\n",
        "        'subject': str,\n",
        "        'from': str,\n",
        "        'to': str,\n",
        "        'cc': str,\n",
        "        'date': str,\n",
        "        'body': str,\n",
        "        'attachments': [ { 'filename': str, 'data': bytes }, ... ]\n",
        "      }\n",
        "    \"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        raw_data = f.read()\n",
        "    msg = email.message_from_bytes(raw_data)\n",
        "\n",
        "    email_data = {\n",
        "        \"subject\": msg.get(\"subject\", \"\"),\n",
        "        \"from\": msg.get(\"from\", \"\"),\n",
        "        \"to\": msg.get(\"to\", \"\"),\n",
        "        \"cc\": msg.get(\"cc\", \"\"),\n",
        "        \"date\": msg.get(\"date\", \"\"),\n",
        "        \"body\": \"\",\n",
        "        \"attachments\": []\n",
        "    }\n",
        "\n",
        "    for part in msg.walk():\n",
        "        filename = part.get_filename()\n",
        "        content_type = part.get_content_type()\n",
        "\n",
        "        # If there's a filename, treat it as attachment\n",
        "        if filename:\n",
        "            attach_data = part.get_payload(decode=True)\n",
        "            email_data[\"attachments\"].append(\n",
        "                {\"filename\": filename, \"data\": attach_data}\n",
        "            )\n",
        "        else:\n",
        "            if content_type in [\"text/plain\", \"text/html\"]:\n",
        "                try:\n",
        "                    body_content = part.get_payload(decode=True)\n",
        "                    if body_content:\n",
        "                        email_data[\"body\"] += body_content.decode(errors=\"ignore\")\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    return email_data\n",
        "\n",
        "#######################################\n",
        "# Utility: extract_text_from_attachments\n",
        "#######################################\n",
        "def extract_text_from_attachments(attachments: List[dict]) -> str:\n",
        "    \"\"\"\n",
        "    For each attachment:\n",
        "      - If PDF, extract text using PyPDF2.\n",
        "      - If DOCX, extract text using python-docx.\n",
        "      - (Optionally, if scanned PDF, can do OCR with Tesseract.)\n",
        "    Return concatenated text from all attachments.\n",
        "    \"\"\"\n",
        "    full_attachment_text = \"\"\n",
        "    for attach in attachments:\n",
        "        filename = attach[\"filename\"].lower()\n",
        "        data = attach[\"data\"]\n",
        "\n",
        "        # PDF extraction\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            try:\n",
        "                pdf_file = PyPDF2.PdfReader(io.BytesIO(data))\n",
        "                pdf_text = []\n",
        "                for page in pdf_file.pages:\n",
        "                    extracted = page.extract_text()\n",
        "                    if extracted:\n",
        "                        pdf_text.append(extracted)\n",
        "                combined_pdf_text = \"\\n\".join(pdf_text)\n",
        "\n",
        "                # If it was a scanned PDF, you could do:\n",
        "                #   - Convert each page to an image\n",
        "                #   - Run pytesseract.image_to_string(image)\n",
        "                # We'll skip that for now.\n",
        "\n",
        "                full_attachment_text += (combined_pdf_text + \"\\n\")\n",
        "            except Exception as e:\n",
        "                full_attachment_text += f\"[PDF error: {e}]\\n\"\n",
        "\n",
        "        # DOCX extraction\n",
        "        elif filename.endswith(\".docx\"):\n",
        "            try:\n",
        "                file_stream = io.BytesIO(data)\n",
        "                doc = docx.Document(file_stream)\n",
        "                docx_text = []\n",
        "                for para in doc.paragraphs:\n",
        "                    if para.text.strip():\n",
        "                        docx_text.append(para.text)\n",
        "                full_attachment_text += (\"\\n\".join(docx_text) + \"\\n\")\n",
        "            except Exception as e:\n",
        "                full_attachment_text += f\"[DOCX error: {e}]\\n\"\n",
        "\n",
        "        else:\n",
        "            # For other file types, handle as needed.\n",
        "            pass\n",
        "\n",
        "    return full_attachment_text\n",
        "\n",
        "#######################################\n",
        "# classify_request_types (Zero-shot)\n",
        "#######################################\n",
        "def classify_request_types(text: str, candidate_labels: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Use the zero-shot classification pipeline to get a probability\n",
        "    for each candidate label.\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return {label: 0.0 for label in candidate_labels}\n",
        "\n",
        "    result = classifier(text, candidate_labels, multi_label=True)\n",
        "    # 'result' has 'labels' and 'scores' in descending order.\n",
        "    scores_dict = {}\n",
        "    for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
        "        scores_dict[label] = score\n",
        "    return scores_dict\n",
        "\n",
        "#######################################\n",
        "# apply_domain_rules\n",
        "#######################################\n",
        "def apply_domain_rules(scores_dict: Dict[str, float]) -> Tuple[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Pick the highest-confidence label subject to domain priority.\n",
        "    Then treat the rest as sub-requests.\n",
        "\n",
        "    Domain priority example:\n",
        "      1. Money Movement-Inbound\n",
        "      2. Money Movement-Outbound\n",
        "      3. Commitment Change\n",
        "      4. Fee Payment\n",
        "      5. Closing Notice\n",
        "      6. AU Transfer\n",
        "      7. Adjustments\n",
        "    \"\"\"\n",
        "    if not scores_dict:\n",
        "        return None, []\n",
        "\n",
        "    # Sort labels by confidence descending\n",
        "    sorted_labels = sorted(scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    priority_order = [\n",
        "        \"Money Movement-Inbound\",\n",
        "        \"Money Movement-Outbound\",\n",
        "        \"Commitment Change\",\n",
        "        \"Fee Payment\",\n",
        "        \"Closing Notice\",\n",
        "        \"AU Transfer\",\n",
        "        \"Adjustments\",\n",
        "    ]\n",
        "\n",
        "    primary = None\n",
        "    sub_list = []\n",
        "    for label, _ in sorted_labels:\n",
        "        # if we haven't picked a primary yet AND label is recognized\n",
        "        if (primary is None) and (label in priority_order):\n",
        "            primary = label\n",
        "        else:\n",
        "            sub_list.append(label)\n",
        "\n",
        "    return primary, sub_list\n",
        "\n",
        "#######################################\n",
        "# extract_key_fields\n",
        "#######################################\n",
        "def extract_key_fields(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Basic example: extract first found $-amount. Optionally add more logic.\n",
        "    \"\"\"\n",
        "    # Regex for amounts like $1,234,567 or 2,000.00 USD\n",
        "    amount_pattern = re.compile(r'(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.?\\d+)?)(?:\\s?(USD|dollars)?)')\n",
        "    matches = amount_pattern.findall(text)\n",
        "    amount = matches[0][0] if matches else None\n",
        "\n",
        "    extracted_fields = {\n",
        "        \"deal_name\": None,         # Could do advanced logic or NER.\n",
        "        \"amount\": amount,\n",
        "        \"expiration_date\": None,   # Could do date regex or NER.\n",
        "    }\n",
        "    return extracted_fields\n",
        "\n",
        "#######################################\n",
        "# check_duplicate (stub)\n",
        "#######################################\n",
        "def check_duplicate(email_data: dict, text: str) -> Tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Simple placeholder for duplicates. You might:\n",
        "      - Track message IDs\n",
        "      - Compare text similarity\n",
        "    Here, we always return False.\n",
        "    \"\"\"\n",
        "    return False, \"\"\n",
        "\n",
        "#######################################\n",
        "# process_email\n",
        "#######################################\n",
        "def process_email(file_path: str, request_types: List[str]) -> dict:\n",
        "    \"\"\"\n",
        "    End-to-end pipeline for a single .eml:\n",
        "      1. parse .eml\n",
        "      2. extract text (body + attachments)\n",
        "      3. classify request types (zero-shot)\n",
        "      4. apply domain rules -> primary + subs\n",
        "      5. extract key fields (amount, etc.)\n",
        "      6. check duplicates\n",
        "      7. return structured result\n",
        "    \"\"\"\n",
        "    eml_data = parse_eml(file_path)\n",
        "    body_text = eml_data[\"body\"] or \"\"\n",
        "\n",
        "    attachments_text = extract_text_from_attachments(eml_data[\"attachments\"])\n",
        "    combined_text = body_text + \"\\n\" + attachments_text\n",
        "\n",
        "    # Classify\n",
        "    scores = classify_request_types(combined_text, request_types)\n",
        "    primary_request, sub_requests = apply_domain_rules(scores)\n",
        "\n",
        "    # Extract fields\n",
        "    extracted_fields = extract_key_fields(combined_text)\n",
        "\n",
        "    # Check duplicates\n",
        "    duplicate_flag, duplicate_reason = check_duplicate(eml_data, combined_text)\n",
        "\n",
        "    if not primary_request:\n",
        "        primary_request = \"Unknown\"  # fallback if no request type matched\n",
        "\n",
        "    output = {\n",
        "        \"filename\": os.path.basename(file_path),\n",
        "        \"primary_request_type\": {\n",
        "            \"label\": primary_request,\n",
        "            \"confidence\": scores.get(primary_request, 0.0),\n",
        "            \"reasoning\": f\"Detected {primary_request} with highest confidence; domain rules applied.\"\n",
        "        },\n",
        "        \"sub_request_types\": [\n",
        "            {\n",
        "                \"label\": sr,\n",
        "                \"confidence\": scores.get(sr, 0.0)\n",
        "            } for sr in sub_requests\n",
        "        ],\n",
        "        \"extracted_fields\": extracted_fields,\n",
        "        \"duplicate_flag\": duplicate_flag,\n",
        "        \"duplicate_reason\": duplicate_reason\n",
        "    }\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Sample EML Files\n",
        "\n",
        "We'll create multiple `.eml` files in a `test_emails` directory. Each email will have a different body and attachments with **meaningful** content. Then, we'll run the pipeline on all of them.\n",
        "\n",
        "**Note**: We'll embed base64-encoded PDFs and DOCXs. Each PDF or DOCX will contain some domain-relevant text, e.g., mention of amounts, request type, or other keywords.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PDF 1: Inbound money movement, Redwood Project\n",
        "PDF1_BASE64 = b\"\"\"\n",
        "JVBERi0xLjUNCiW1t7IKDQoxIDAgb2JqDTw8IC9DcmVhdG9yIChHb29nbGUgQ29sYWIpCi9QYWdl\n",
        "cyAyIDAgUgovVHlwZS9DYXRhbG9nPj4NZW5kb2JqDQoyIDAgb2JqDTw8IC9Db3VudCAxIC9LaWRz\n",
        "IFszIDAgUl0gL1R5cGUgL1BhZ2VzPj4NZW5kb2JqDQozIDAgb2JqDTw8IC9Db250ZW50cyA0IDAg\n",
        "UiAvUGFyZW50IDIgMCBSIC9UeXBlIC9QYWdlPj5lbmRvYmoNCjQgMCBvYmoNPDwgL0xlbmd0aCAx\n",
        "NDc+PnN0cmVhbQpUaGlzIFBERiBjb250YWlucyBhbiBpbmJvdW5kIG1vbmV5IG1vdmVtZW50IHJl\n",
        "cXVlc3QgZm9yIFJlZHdvb2QgUHJvamVjdC4KCklubmVyIFRleHQ6IFJlcXVlc3RpbmcgJDIuNTAw\n",
        "LDAwMCBmb3IgUmVkd29vZCBQcm9qZWN0LCB0byBiZSBmb3JtYWxseSBpbml0aWF0ZWQgb24gMjAy\n",
        "NS0xMi0wMS4KCkZlZWVzOiBUaGlzIGlzIGNsYXNzaWZpZWQgYXMgYW4gTW9uZXkgTW92ZW1lbnQt\n",
        "SW5ib3VuZCByZXF1ZXN0LgoNCkVuZCBvZiBQQ0YNCmVuZHN0cmVhbQplbmRvYmoNCnhyZWYNCjAg\n",
        "MTUNCjAwMDAwMDAwMDAgNjU1MzUgZiANCjAwMDAwMDAwMTAgMDAwMDAgbiANCjAwMDAwMDAwNTAg\n",
        "MDAwMDAgbiANCjAwMDAwMDAwOTAgMDAwMDAgbiANCnRyYWlsZXINCjw8IC9TaXplIDUgL1Jvb3Qg\n",
        "MSAwIFIgL0luZm8gNiAwIFIgL0lEIFsgPDZiYTg0MGEyNmI5OGI5YWFiODQyZDQ0ODgwNzQzMzAw\n",
        "Mj4gPDZiYTg0MGEyNmI5OGI5YWFiODQyZDQ0ODgwNzQzMzAwMj5dID4+DQpzdGFydHhyZWYNCjUx\n",
        "OQ0KJSVFT0YNCg==\n",
        "\"\"\"\n",
        "\n",
        "# DOCX 1: Redwood Project doc with some references\n",
        "DOCX1_BASE64 = b\"\"\"\n",
        "UEsDBBQABgAIAAAAIQDKgTJisAEAAB4FAAAQABwAUmVkd29vZC5kb2N4AAAAAAAAAAAAAAAAAAAA\n",
        "AAAAAAAAAAAAAAAAhrJiWVPQy9KTSxJVcjPTM0HczQwMDY2YpgBAkLEgQMAYzh5IQbKdyI9pNgp2\n",
        "LxRJFVtlPxBiCfF1h3sO0mkPDI94RZbXWxchQmqB6dvzK1AR3FU7dKxOSnImsVM5fgy0ND/orybC\n",
        "93jST6AUEsBAh4DFAAGAAgAAAAhAMqBMmKwAQAAHgUAABAAAAAAAAAAAAAAAAAAAAAAAACAAAAA\n",
        "AFJlZHdvb2QuZG9jeFBLBQYAAAAAAQABAEcAAAD2AAAAAAA=\"\"\"\n",
        "\n",
        "# PDF 2: Mentions an Adjustment of $500 for Amendment Fees\n",
        "PDF2_BASE64 = b\"\"\"\n",
        "JVBERi0xLjUNCiW1t7IKDQoxIDAgb2JqDTw8IC9DcmVhdG9yIChHb29nbGUgQ29sYWIpCi9QYWdl\n",
        "cyAyIDAgUgovVHlwZS9DYXRhbG9nPj4NZW5kb2JqDQoyIDAgb2JqDTw8IC9Db3VudCAxIC9LaWRz\n",
        "IFszIDAgUl0gL1R5cGUgL1BhZ2VzPj4NZW5kb2JqDQozIDAgb2JqDTw8IC9Db250ZW50cyA0IDAg\n",
        "UiAvUGFyZW50IDIgMCBSIC9UeXBlIC9QYWdlPj5lbmRvYmoNCjQgMCBvYmoNPDwgL0xlbmd0aCAx\n",
        "Mjc+PnN0cmVhbQpUaGlzIGRvY3VtZW50IG91dGxpbmVzIGFuIGFkanVzdG1lbnQgcmVxdWVzdC4K\n",
        "CldlIGFyZSBhc2tpbmcgZm9yIGFuICQ1MDAgQW1lbmRtZW50IEZlZS4KCkl0IHNob3VsZCBiZSBw\n",
        "cmlvcml0aXplZCAgYWJvdmUgb3RoZXIgc2VydmljZSByZXF1ZXN0cy4KCkVuZCBvZiBkb2N1bWVu\n",
        "dA0KZW5kc3RyZWFtDQplbmRvYmoNCnhyZWYNCjAgMTUNCjAwMDAwMDAwMDAgNjU1MzUgZiANCjAw\n",
        "MDAwMDAwMTAgMDAwMDAgbiANCjAwMDAwMDAwNTAgMDAwMDAgbiANCjAwMDAwMDAwOTAgMDAwMDAg\n",
        "biANCnRyYWlsZXINCjw8IC9TaXplIDUgL1Jvb3QgMSAwIFIgL0luZm8gNiAwIFIgL0lEIFsgPDY0\n",
        "MjM0MDczMjBmYTE1ZjJkZWMyZTQzZTU5NTI2NzUwZT4gPDY0MjM0MDczMjBmYTE1ZjJkZWMyZTQz\n",
        "ZTU5NTI2NzUwZT5dID4+DQpzdGFydHhyZWYNCjUxOQ0KJSVFT0YNCg==\n",
        "\"\"\"\n",
        "\n",
        "# DOCX 2: Mentions an \"Adjustment\" for $500 - Word doc.\n",
        "DOCX2_BASE64 = b\"\"\"\n",
        "UEsDBBQABgAIAAAAIQDmTaC9tgEAADcFAAAOABwAQWRqdXN0bWVudC5kb2N4AAAAAAAAAAAAAAAA\n",
        "AAAAAAC0O2EK7M3JTczRbKyIVbIKjeUCAuERggA2QiAQAUEsDBBQABgAIAAAAIQDmTaC9tgEAADcF\n",
        "AAAQABwAd29yZC9fcmVscy9kb2N1bWVudC54bWwucmVscwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
        "AHRCRgpQSwECHgMUAAYACAAAACEA5k2gvbYBAAA3BQAAFgAAAAAAAAAAAAAAAAAkAAAAAEFkanVz\n",
        "dG1lbnQuZG9jeFBLAQIeAxQABgAIAAAAIQDmTaC9tgEAADcFAAAQAAAAAAAAAAAAAAAAAAgAAQAA\n",
        "AHdvcmQvX3JlbHMvZG9jdW1lbnQueG1sLnJlbHNUQkYKlBLAQIeAxQABgAIAAAAIQDmTaC9tgEA\n",
        "AA==\"\"\"\n",
        "\n",
        "##################################################################\n",
        "#  Helper function to write sample .eml with attachments\n",
        "##################################################################\n",
        "\n",
        "def create_eml_file(\n",
        "    file_path: str,\n",
        "    subject: str,\n",
        "    body_text: str,\n",
        "    attachments: List[Tuple[str, bytes]]\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Create an .eml file with the given subject, body_text, and a list of\n",
        "    attachments (filename, base64 bytes).\n",
        "    \"\"\"\n",
        "    boundary = \"BOUNDARY\"\n",
        "    # Basic EML header\n",
        "    eml_header = f\"\"\"From: hackathon.user@example.com\\n\" \\\n",
        "                  f\"To: genai.challenge@example.com\\n\" \\\n",
        "                  f\"Subject: {subject}\\n\" \\\n",
        "                  f\"MIME-Version: 1.0\\n\" \\\n",
        "                  f\"Content-Type: multipart/mixed; boundary=\\\"{boundary}\\\"\\n\" \\\n",
        "                  f\"\\n\"\"\".strip()\n",
        "\n",
        "    # Body part\n",
        "    eml_body = f\"--{boundary}\\nContent-Type: text/plain\\n\\n{body_text}\\n\\n\"\n",
        "\n",
        "    # Attachments part\n",
        "    eml_attachments = \"\"\n",
        "    for (fname, b64data) in attachments:\n",
        "        if fname.lower().endswith(\".pdf\"):\n",
        "            content_type = \"application/pdf\"\n",
        "        elif fname.lower().endswith(\".docx\"):\n",
        "            content_type = \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "        else:\n",
        "            content_type = \"application/octet-stream\"\n",
        "\n",
        "        eml_attachments += (f\"--{boundary}\\n\"\n",
        "                            f\"Content-Type: {content_type}\\n\"\n",
        "                            f\"Content-Transfer-Encoding: base64\\n\"\n",
        "                            f\"Content-Disposition: attachment; filename=\\\"{fname}\\\"\\n\"\n",
        "                            f\"\\n\"\n",
        "                            f\"{b64data.decode('utf-8')}\\n\\n\")\n",
        "\n",
        "    # Closing boundary\n",
        "    eml_close = f\"--{boundary}--\\n\"\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(eml_header + \"\\n\\n\")\n",
        "        f.write(eml_body)\n",
        "        f.write(eml_attachments)\n",
        "        f.write(eml_close)\n",
        "\n",
        "# Now let's create a test_emails directory and populate multiple .eml files.\n",
        "\n",
        "os.makedirs(\"test_emails\", exist_ok=True)\n",
        "\n",
        "# 1) EML for Inbound Money Movement\n",
        "body_1 = (\"Hello Loan Team,\\n\\n\"\n",
        "          \"Requesting a Money Movement-Inbound for $2,500,000.\\n\"\n",
        "          \"See attached PDF & DOCX for Redwood Project details.\\n\\n\"\n",
        "          \"Best Regards,\\nClient XYZ\")\n",
        "\n",
        "create_eml_file(\n",
        "    file_path=\"test_emails/email_inbound.eml\",\n",
        "    subject=\"Inbound Funding Request - Redwood Project\",\n",
        "    body_text=body_1,\n",
        "    attachments=[\n",
        "        (\"redwood_funding.pdf\", PDF1_BASE64),\n",
        "        (\"redwood_details.docx\", DOCX1_BASE64)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 2) EML for Adjustments / Amendment Fee\n",
        "body_2 = (\"Dear Servicing Team,\\n\\n\"\n",
        "          \"We would like to request an Adjustment in the amount of $500 for Amendment Fees.\\n\"\n",
        "          \"Please review the attached PDF and DOCX.\\n\\n\"\n",
        "          \"Thanks,\\nAccount Manager\")\n",
        "\n",
        "create_eml_file(\n",
        "    file_path=\"test_emails/email_adjustment.eml\",\n",
        "    subject=\"Adjustment Request - Amendment Fees\",\n",
        "    body_text=body_2,\n",
        "    attachments=[\n",
        "        (\"amendment_fees.pdf\", PDF2_BASE64),\n",
        "        (\"adjustment_details.docx\", DOCX2_BASE64)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 3) EML referencing multiple requests but we want to see which is primary\n",
        "#    We'll mention both \"money movement inbound\" and \"fee payment\" in the text.\n",
        "\n",
        "body_3 = (\"Hello,\\n\\n\"\n",
        "          \"We need a Fee Payment processed tomorrow, and also plan to do a Money Movement-Inbound.\\n\"\n",
        "          \"However, the inbound request is the priority.\\n\\n\"\n",
        "          \"Regards,\\nClient ABC\")\n",
        "\n",
        "create_eml_file(\n",
        "    file_path=\"test_emails/email_multiple.eml\",\n",
        "    subject=\"Fee Payment & Inbound Movement\",\n",
        "    body_text=body_3,\n",
        "    attachments=[]  # no attachments for this one\n",
        ")\n",
        "\n",
        "print(\"Sample EML files created in ./test_emails\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run the Pipeline on All `.eml` Files in `test_emails`\n",
        "\n",
        "We'll define our sample request types, iterate over each `.eml` file, parse & classify, then collect the results in a **report**.\n",
        "\n",
        "Finally, we'll display the output as JSON.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the known request types\n",
        "SAMPLE_REQUEST_TYPES = [\n",
        "    \"Adjustments\",\n",
        "    \"AU Transfer\",\n",
        "    \"Closing Notice\",\n",
        "    \"Commitment Change\",\n",
        "    \"Fee Payment\",\n",
        "    \"Money Movement-Inbound\",\n",
        "    \"Money Movement-Outbound\"\n",
        "]\n",
        "\n",
        "# Collect results in a list\n",
        "report = []\n",
        "\n",
        "# Iterate over all .eml files in test_emails\n",
        "eml_files = [f for f in os.listdir(\"test_emails\") if f.lower().endswith(\".eml\")]\n",
        "for eml_file in eml_files:\n",
        "    eml_path = os.path.join(\"test_emails\", eml_file)\n",
        "    result = process_email(eml_path, SAMPLE_REQUEST_TYPES)\n",
        "    report.append(result)\n",
        "\n",
        "# Print the final report as JSON\n",
        "print(\"\\n==================== Final Report ====================\")\n",
        "print(json.dumps(report, indent=2))\n",
        "print(\"=====================================================\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
